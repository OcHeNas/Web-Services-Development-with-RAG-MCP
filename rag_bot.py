import os
from pathlib import Path
import logging
import nest_asyncio
import requests
from dotenv import load_dotenv
from telegram import Update
from telegram.ext import (
    Application,
    CommandHandler,
    MessageHandler,
    ContextTypes,
    filters,
)

# ================== –ù–ê–°–¢–†–û–ô–ö–ê ==================

load_dotenv()

TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
if not TELEGRAM_TOKEN:
    raise ValueError("–û—à–∏–±–∫–∞: TELEGRAM_TOKEN –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ .env")

LM_STUDIO_CHAT_URL = "http://127.0.0.1:1234/api/v1/chat"
MODEL_NAME = "mistralai/mistral-7b-instruct-v0.3"

logging.basicConfig(
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    level=logging.INFO,
)
logger = logging.getLogger(__name__)

nest_asyncio.apply()

# ================== –ó–ê–ì–†–£–ó–ö–ê –î–û–ö–£–ú–ï–ù–¢–û–í ==================

DOCS_DIR = Path("documents")
DOCS_DIR.mkdir(exist_ok=True)


def load_documents():
    docs = []
    for file_path in DOCS_DIR.iterdir():
        if file_path.is_file() and file_path.suffix.lower() == ".txt":
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()
            docs.append(
                {
                    "filename": file_path.name,
                    "content": content,
                }
            )
            print(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω: {file_path.name} ({len(content)} —Å–∏–º–≤–æ–ª–æ–≤)")
    print(f"\n–í—Å–µ–≥–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(docs)}")
    return docs


documents = load_documents()


def build_context(docs):
    return "\n\n".join(
        f"=== –î–æ–∫—É–º–µ–Ω—Ç: {doc['filename']} ===\n{doc['content']}"
        for doc in docs
    )


DOCUMENTS_CONTEXT = build_context(documents)

SYSTEM_PROMPT = f"""–¢—ã ‚Äî –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã —Å—Ç—Ä–æ–≥–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.

–£ —Ç–µ–±—è –µ—Å—Ç—å –¥–æ—Å—Ç—É–ø –∫ —Å–ª–µ–¥—É—é—â–∏–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º:

{DOCUMENTS_CONTEXT}

–ü—Ä–∞–≤–∏–ª–∞:
1. –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤—ã—à–µ
2. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ—Ç –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö, —á–µ—Å—Ç–Ω–æ —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º
3. –£–∫–∞–∑—ã–≤–∞–π, –∏–∑ –∫–∞–∫–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤–∑—è—Ç–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
4. –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ç–æ–º –∂–µ —è–∑—ã–∫–µ, –Ω–∞ –∫–æ—Ç–æ—Ä–æ–º –∑–∞–¥–∞–Ω –≤–æ–ø—Ä–æ—Å
"""

print(f"–°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å–æ–∑–¥–∞–Ω ({len(SYSTEM_PROMPT)} —Å–∏–º–≤–æ–ª–æ–≤)")

# ================== –ó–ê–ü–†–û–° –ö LM STUDIO (/api/v1/chat) ==================

def ask_question(question: str) -> str:
    """
    –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ LM Studio natively —á–µ—Ä–µ–∑ /api/v1/chat
    """
    try:
        payload = {
            "model": MODEL_NAME,
            "messages": [
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": question},
            ],
            "temperature": 0.7,
            "max_output_tokens": 1000,
        }

        response = requests.post(LM_STUDIO_CHAT_URL, json=payload, timeout=120)
        response.raise_for_status()
        data = response.json()

        # LM Studio chat API –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ç–≤–µ—Ç –≤ ['response']
        if "response" in data:
            return data["response"]
        else:
            return "‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏."

    except Exception as e:
        logger.exception("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ LM Studio")
        return f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {e}"


# ================== TELEGRAM HANDLERS ==================

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "–ü—Ä–∏–≤–µ—Ç! üëã –Ø RAG-–±–æ—Ç —Å –ª–æ–∫–∞–ª—å–Ω–æ–π LLM (LM Studio).\n\n"
        "–ö–æ–º–∞–Ω–¥—ã:\n"
        "/start ‚Äî –Ω–∞—á–∞–ª–æ —Ä–∞–±–æ—Ç—ã\n"
        "/status ‚Äî —Å—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã\n\n"
        "–ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏—Ç–µ –≤–æ–ø—Ä–æ—Å ‚Äî —è –æ—Ç–≤–µ—á—É –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤."
    )


async def status(update: Update, context: ContextTypes.DEFAULT_TYPE):
    docs_count = len(documents)
    try:
        requests.post(
            LM_STUDIO_CHAT_URL,
            json={
                "model": MODEL_NAME,
                "messages": [{"role": "user", "content": "ping"}],
                "max_output_tokens": 1,
            },
            timeout=10,
        )
        lm_status = "‚úÖ –ø–æ–¥–∫–ª—é—á–µ–Ω"
    except Exception as e:
        lm_status = f"‚ùå –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω ({e})"

    await update.message.reply_text(
        "üìä –°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã:\n\n"
        f"LM Studio: {lm_status}\n"
        f"–î–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {docs_count}\n"
        f"–ú–æ–¥–µ–ª—å: {MODEL_NAME}"
    )


async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not documents:
        await update.message.reply_text(
            "‚ö† –î–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã.\n"
            "–î–æ–±–∞–≤—å—Ç–µ .txt —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫—É 'documents/' –∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ –±–æ—Ç–∞."
        )
        return

    question = update.message.text
    await update.message.reply_text("ü§î –î—É–º–∞—é...")
    answer = ask_question(question)
    await update.message.reply_text(answer)


# ================== –ó–ê–ü–£–°–ö –ë–û–¢–ê ==================

def run_bot():
    application = Application.builder().token(TELEGRAM_TOKEN).build()

    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("status", status))
    application.add_handler(
        MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message)
    )

    application.run_polling(allowed_updates=Update.ALL_TYPES)


if __name__ == "__main__":
    run_bot()







