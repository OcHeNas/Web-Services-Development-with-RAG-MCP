import os
from pathlib import Path
import logging
import nest_asyncio
from dotenv import load_dotenv
from openai import OpenAI
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, ContextTypes, filters

# ========== –ù–∞—Å—Ç—Ä–æ–π–∫–∞ ==========

load_dotenv()

TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
LM_STUDIO_BASE_URL = os.getenv("LM_STUDIO_URL", "http://localhost:1234/v1")

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–æ–∫–µ–Ω–∞
if TELEGRAM_TOKEN is None:
    raise ValueError("–û—à–∏–±–∫–∞: TELEGRAM_TOKEN –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ .env")

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    level=logging.INFO,
)
logger = logging.getLogger(__name__)
nest_asyncio.apply()

# –ö–ª–∏–µ–Ω—Ç LM Studio
client = OpenAI(base_url=LM_STUDIO_BASE_URL, api_key="lm-studio")

# ========== –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ ==========

DOCS_DIR = Path("documents")
DOCS_DIR.mkdir(exist_ok=True)

def load_documents():
    documents = []
    for file_path in DOCS_DIR.iterdir():
        if file_path.is_file() and file_path.suffix.lower() == ".txt":
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()
            documents.append({"filename": file_path.name, "content": content})
            print(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω: {file_path.name} ({len(content)} —Å–∏–º–≤–æ–ª–æ–≤)")
    print(f"\n–í—Å–µ–≥–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(documents)}")
    return documents

documents = load_documents()

def build_context(documents):
    context_parts = [f"=== –î–æ–∫—É–º–µ–Ω—Ç: {doc['filename']} ===\n{doc['content']}" for doc in documents]
    return "\n\n".join(context_parts)

context = build_context(documents)

SYSTEM_PROMPT = f"""–¢—ã - –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.

–£ —Ç–µ–±—è –µ—Å—Ç—å –¥–æ—Å—Ç—É–ø –∫ —Å–ª–µ–¥—É—é—â–∏–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º:

{context}

–ü—Ä–∞–≤–∏–ª–∞:
1. –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤—ã—à–µ
2. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ—Ç –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö, —á–µ—Å—Ç–Ω–æ —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º
3. –£–∫–∞–∑—ã–≤–∞–π, –∏–∑ –∫–∞–∫–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤–∑—è—Ç–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
4. –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ç–æ–º –∂–µ —è–∑—ã–∫–µ, –Ω–∞ –∫–æ—Ç–æ—Ä–æ–º –∑–∞–¥–∞–Ω –≤–æ–ø—Ä–æ—Å
"""

print(f"–°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å–æ–∑–¥–∞–Ω ({len(SYSTEM_PROMPT)} —Å–∏–º–≤–æ–ª–æ–≤)")

# ========== –§—É–Ω–∫—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞ –∫ LM Studio ==========

def ask_question(question: str) -> str:
    try:
        response = client.chat.completions.create(
            model="local-model",
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": question}
            ],
            temperature=0.7,
            max_tokens=1000
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {e}"

# ========== –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ Telegram ==========

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "–ü—Ä–∏–≤–µ—Ç! –Ø RAG-–±–æ—Ç —Å LM Studio.\n\n"
        "–ö–æ–º–∞–Ω–¥—ã:\n"
        "/start - –ù–∞—á–∞–ª–æ —Ä–∞–±–æ—Ç—ã\n"
        "/status - –°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã\n\n"
        "–ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏—Ç–µ –≤–æ–ø—Ä–æ—Å, –∏ —è –æ—Ç–≤–µ—á—É –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤."
    )

async def status(update: Update, context: ContextTypes.DEFAULT_TYPE):
    docs_count = len(documents)
    try:
        client.models.list()
        lm_status = "+ –ø–æ–¥–∫–ª—é—á–µ–Ω"
    except:
        lm_status = "- –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"
    await update.message.reply_text(
        f"–°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã:\n\n"
        f"LM Studio: {lm_status}\n"
        f"–î–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {docs_count}\n"
        f"URL: {LM_STUDIO_BASE_URL}"
    )

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not documents:
        await update.message.reply_text(
            "‚ö† –î–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã.\n–î–æ–±–∞–≤—å—Ç–µ .txt —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫—É 'documents/' –∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ —Å–∫—Ä–∏–ø—Ç."
        )
        return
    
    question = update.message.text
    await update.message.reply_text("ü§î –î—É–º–∞—é...")
    answer = ask_question(question)
    await update.message.reply_text(answer)

# ========== –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞ ==========

def run_bot():
    application = Application.builder().token(TELEGRAM_TOKEN).build()
    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("status", status))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    application.run_polling(allowed_updates=Update.ALL_TYPES)

if __name__ == "__main__":
    run_bot()
